{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook analyzes baseball pitches to predict a batter's swing probability using data from three seasons. It processes the data by handling missing values, \n",
    "one-hot encoding categorical variables, and ensuring consistency between training and testing datasets.\n",
    "\n",
    "Key functionalities include:\n",
    "\n",
    "- Calculating Variance Inflation Factor (VIF) to check for multicollinearity.\n",
    "- Optimizing a RandomForestClassifier with GridSearchCV based on ROC AUC scores.\n",
    "- Evaluating model performance with metrics like ROC AUC, accuracy, confusion matrices, and generating ROC curves.\n",
    "- Visualizing feature importance to highlight influential factors in the modelâ€™s predictions.\n",
    "- Saving the best model and updating the dataset with predicted probabilities for further validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check multicolinearity amongst features\n",
    "def calculate_vifs(df):\n",
    "    # Adding a constant column for intercept\n",
    "    df = add_constant(df)\n",
    "    \n",
    "    # Calculating VIF for each feature\n",
    "    vifs = pd.DataFrame()\n",
    "    vifs[\"Variable\"] = df.columns\n",
    "    vifs[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    \n",
    "    return vifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read, preprocess and split data into train-test. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_season1 = pd.read_csv('year1.csv')\n",
    "data_season2 = pd.read_csv('year2.csv')\n",
    "data_season3 = pd.read_csv('year3.csv')\n",
    "# Combine season 1 and 2 for training\n",
    "data_train = pd.concat([data_season1, data_season2], ignore_index=True)\n",
    "# since we have a lot of data, we can drop the rows win NaN values\n",
    "data_train = data_train.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar process for season 3. For all rows with NaN values, Swing Probability is assigned as 0.5\n",
    "nan_rows = data_season3.isna().any(axis=1)\n",
    "data_season3['SwingProbability'] = 0.5\n",
    "data_season3_clean = data_season3.dropna(axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define swing events\n",
    "swing_events = ['foul', 'hit_into_play', 'swinging_strike', 'foul_tip',\n",
    "                'foul_bunt', 'swinging_strike_blocked', 'missed_bunt', 'bunt_foul_tip','foul_pitchout']\n",
    "\n",
    "# create a new column to specify if batter swung or not\n",
    "data_train['swing'] = data_train['description'].apply(lambda x: 1 if x in swing_events else 0)\n",
    "\n",
    "# create a new feature and add it to both training data and season 3 data\n",
    "data_train['relative_pitch_height'] = (data_train['plate_z'] - data_train['sz_bot']) / (data_train['sz_top'] - data_train['sz_bot'])\n",
    "data_season3_clean['relative_pitch_height'] = (data_season3_clean['plate_z'] - data_season3_clean['sz_bot']) / (data_season3_clean['sz_top'] - data_season3_clean['sz_bot'])\n",
    "\n",
    "# pick the features for the model and one-hot encode the categorical features\n",
    "features = ['release_speed', 'plate_x','stand','p_throws','pfx_x', 'pfx_z','balls', 'strikes', 'pitch_type', 'relative_pitch_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(data_train[features], drop_first=True)\n",
    "X_test = pd.get_dummies(data_season3_clean[features], drop_first=True)\n",
    "\n",
    "# Ensure the same dummy variable columns in train and test\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Prepare target\n",
    "y_train = data_train['swing']\n",
    "\n",
    "# Split the data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = calculate_vifs(X_train)\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {'n_estimators': [50, 100, 200, 300], 'max_depth': [10, 15, 20, 25, 30]}\n",
    "param_grid = {'n_estimators': [300], 'max_depth': [25]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# pick the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluations and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on validation data\n",
    "y_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "y_pred = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))    \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='cornflowerblue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = X_train.columns\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\", color=\"navy\")\n",
    "plt.xticks(range(X_train.shape[1]), features[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "with open('best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "    \n",
    "# Predict for season 3\n",
    "data_season3_clean['SwingProbability'] = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "data_season3.update(data_season3_clean)\n",
    "\n",
    "# Save the validation file\n",
    "data_season3.to_csv('validation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
